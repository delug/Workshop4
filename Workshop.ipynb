{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: \n",
    "\n",
    "Neural Networks (NN) are a very broad category of algorithms and models whose designs were inspired by the patterns and complexities of the human mind. The design philosophy behind NN is fairly simple: iteratively stack relatively simple components to build a significantly more complex model.\n",
    "\n",
    "Mathematically, NN are considered functions from one space to another. Hence, their operation greatly depends on the concepts of Jacobians, Chain Rule, Computational Graphs, all of which are collectively applied in a technique known as backpropagation. \n",
    "\n",
    "Partially based off of http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "\n",
    "## Perceptrons (Binary Classifier)\n",
    "\n",
    "To begin with, we'll define and discuss the first and simplest component of Neural Networks: a perceptron. Perceptrons are basic binary classifierss which serve as a conceptual basis for Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Perceptron](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what we see above. First, we have our inputs $x_1,x_2,\\dots,x_n$. These are whatever variables or features you will be working with, alongside an extra constant $w_0$ known as a *bias*. Generally the bias is optional, but favored. Each input, including the bias, is  multiplied against its own personal *weight* $w_1,w_2,\\dots,w_n$. These weights are also known as parameters, and we'll be using them interchangeably. The products of inputs and weights is then summed together to get $\\sum_{i=1}^nx_iw_i$, and finally that total is *activated*, which means it has an *activation function* applied to it. In the case of a vanilla perceptron, the activation function is a basic step function: \n",
    "\n",
    "$$\n",
    "\\sigma:\\mathbb{R}\\to\\mathbb{R}\\\\ \n",
    "\\sigma(x)=0\\text{ if }x\\leq 0\\text{ otherwise }\\sigma(x)=1\n",
    "$$\n",
    "\n",
    "Generally though this step function doesn't see actual use. Instead, the sigmoid function is favored: \n",
    "$$\n",
    "\\sigma:\\mathbb{R}\\to\\mathbb{R}\\\\ \n",
    "\\sigma(x)=\\frac{1}{1+e^{-x}}\n",
    "$$ \n",
    "\n",
    "It serves a very similar purpose, but unlike a step function, its smooth everywhere. This means that it's differentiable, which will be key for the model.\n",
    "\n",
    "\n",
    "So let's formalize what our perceptron does mathematically. Let's start without a bias. We can consider our inputs as a vector $\\vec x\\in\\mathbb{R}^n$ where $\\vec x=[x_1,x_2,\\dots,x_n]^T$, and similarly our weights as a vector: $\\vec w\\in\\mathbb{R}^n$ with $\\vec w=[w_1,w_2,\\dots,w_n]^T$ then we get that our weighted sum is $\\sum_{i=1}^nx_iw_i=\\vec x\\cdot\\vec w= \\vec w^T\\vec x$. If we include our bias, the only difference we make to this equation is that we define $\\vec x=[1,x_1,x_2,\\dots,x_n]^T$ and our weights as $\\vec w=[w_0,w_1,w_2,\\dots,w_n]^T$. This definition becomes especially convenient later when building up large Neural Networks. \n",
    "\n",
    "We can consider our perceptron as a function \n",
    "$$\n",
    "F: \\mathbb{R}^n\\to\\mathbb{R}\\\\\n",
    "F(\\vec x,\\vec w)=\\sigma(\\vec w^T\\vec x)\n",
    "$$\n",
    "\n",
    "The real question is now: how do we figure out our weights? Well we start by defining some cost function. For simplicity, we'll be using an $L^2$ cost function. For every input $\\vec x_i$ there is an accompanying value known as a *label* or *target* which is what we hope our model will output, written as $y_i\\in\\mathbb{R}$. Then the cost for a particular input is \n",
    "$$\n",
    "C:\\mathbb{R}^n\\to\\mathbb{R}\\\\\n",
    "C(\\vec x_i, \\vec w)=(F(\\vec x_i,\\vec w)-y_i)^2\n",
    "$$\n",
    "\n",
    "This is essentially the *distance* between the model output $\\hat x_i=F(\\vec x_i,\\vec w)$ and the target $y_i$. Now we want to minimize the distance between those two values, so we can apply gradient descent! In order to do that, first we must figure out what the gradient is. As a reminder, what we want is the Jacobian of $L$ with respect to $\\vec w$, written as $(\\mathcal{D}L)$. Note we'll be omitting the arguments to the functions, since those won't change until the last couple steps. Let's worth that out.\n",
    "\n",
    "$$\n",
    "\\mathcal{D}[C]=\\mathcal{D}[(F-y_i)^2]\n",
    "\\\\=2(F-y_i)*\\mathcal{D}[F-y_i]\n",
    "\\\\=2(F-y_i)*(\\mathcal{D}[F]-\\mathcal{D}[y_i])\n",
    "\\\\=2(F-y_i)*\\mathcal{D}[F]\n",
    "$$\n",
    "\n",
    "So now in particular, we'll focus on the $\\mathcal{D}[F]$ term. \n",
    "\n",
    "**Note**: For convenience, we will set a variable $S=\\vec w^T\\vec x=\\vec x^T\\vec w$ \n",
    "$$\n",
    "\\mathcal{D}[F]=\\mathcal{D}[\\sigma(S)]\n",
    "=(\\mathcal{D}[\\sigma])(S)\\mathcal{D}[S]\n",
    "=(\\sigma(S)(1-\\sigma(S))\\vec x^T\n",
    "$$\n",
    "\n",
    "Plugging this back into our equation for \n",
    "$$\n",
    "\\mathcal{D}[C]=2(F-y_i)*\\mathcal{D}[F]=2(F-y_i)*(\\sigma(S)(1-\\sigma(S))\\vec x^T\n",
    "\\\\=2(\\sigma(S)-y_i)*(\\sigma(S)(1-\\sigma(S))\\vec x^T\n",
    "$$\n",
    "\n",
    "Let's take a step back. Remember, we want to figure out *how much to change* $\\vec w$ in order to minimize $L$. Now that we know $\\mathcal{D}[C]$, we know the direction of *greatest increase*, so to minimize it, we only need to step in the opposite direction, $-\\mathcal{D}[C]$. So we know the direction, but how large should our step be? The smaller the step, the more carefuly the algorithm will hone in on its closest local minima. This leads to slower, less noisy training. Setting the step size to be too low will lead to the model spending way too much time training, and likely getting stuck in the first local minima it finds. In practice, this can lead to very poor models. A larger step size leads to faster, noisier training. This noise can *knock* the model out of a local minima, causing it to optimize in other directions. Setting the learning rate to be too large can lead to unstable, non-reproducible training that either diverges, or fails to converge to any minima at all.\n",
    "\n",
    "Unfortunately, there's no golden rule to setting learning rate. Repeated experiments are really the only way to tell what work. There are some heuristics however. The larger the batch size, the greater you want your learning rate to be. If you don't intend to train the model for a long time, then longer steps are encouraged. It generally depends on the exact problem and ciscumstances of your model.\n",
    "\n",
    "For now, let's say that our learning rate $\\epsilon=10^{-3}$. Then in order to update our weights, we will set $w_{new}=w_{old}-\\epsilon\\mathcal{D}[C]$. This seems very small, but generally this process will be repeated anywhere from millions to billions of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, we can define **training** to be the following process:\n",
    "+ Calculate $\\hat y=F(\\vec x,\\vec w)=\\sigma(\\vec w^T\\vec x)$\n",
    "+ Calculate $C(\\vec x_i, \\vec w)=(F(\\vec x_i,\\vec w)-y_i)^2$\n",
    "+ Calculate $\\mathcal{D}[C]$\n",
    "+ Update weights using $w_{new}=w_{old}-\\epsilon\\mathcal{D}[C]$\n",
    "+ Repeat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classifier\n",
    "\n",
    "Consider an example problem of handwritten digit classification. That is to say, you're provided with a $28x28$ image which depicts some digit $0-9$ on it, and your job is to build a model to determine which digit it is. For example:\n",
    "\n",
    "![MNIST](images/MNISTExample.png)\n",
    "\n",
    "\n",
    "This is a very common *first task* in machine learning and deep learning. It's fairly easy to get an *adequate* to *good* model for this task, but difficult to get an *amazing* model, so it is a favored task by those starting out in deep learning. Today we'll tackle this task using our perceptrons! Now, originally a perceptron is only a binary classifier, but the MNIST dataset has 10 classes -- one for each digit. The solution to this is to set up 10 binary classifiers in parallel, with each one making a binary classification as to whether or not the image is a certain digit. For example, perceptron 4 is a binary classifier on whether or not the image is a 4. Perceptron 6 decides whether or not the image is a 6. Each perceptron will take in the $28x28$ image in the form of a $784$-dimensional vector (note: $28x28=784$)\n",
    "\n",
    "Usually a perceptron's classification is **YES** if the result is $\\geq .5$ and **NO** otherwise. The issue with a multi-perceptron setup like the one we'll use is that we can have *more than one* perceptron with a positive classification. To solve this, we must remember what the resulting value actually represents: the models *confidence* regarding its choice. Using this, for the multiclass classifier, we simply take the *largest* value of the various perceptrons.\n",
    "\n",
    "With that being said, it can still lead to issues where we have multiple high-confidence perceptrons, meaning that the sum of all end confidences can be greater than 1. That means that we can no longer consider them probabilities. To fix this, and normalize the outputs, we apply the **softmax** function $$softmax(z)_i=\\frac{z_i}{\\sum_{j=1}^kz_j}$$ We won't discuss the semantincs of the function too much, but just think of it as a function which transforms regular perceptron outputs into a multi-class probability.\n",
    "\n",
    "Let's formalize what weve discussed. Before, we had a function to represent our network as:\n",
    "$$\n",
    "F: \\mathbb{R}^n\\to\\mathbb{R}\\\\\n",
    "F(\\vec x,\\vec w)=\\sigma(\\vec w^T\\vec x)\n",
    "$$\n",
    "\n",
    "but now we need our function to instead look like\n",
    "$$\n",
    "F: \\mathbb{R}^n\\to\\mathbb{R}^{10}\\\\\n",
    "$$\n",
    "\n",
    "where the output dimensions equal the number of classes we have. Then, for $y=F(\\vec x, W)$, we get that $y_i=$the probability that the image $x$ represents the digit $i$. Notice I represent the weights with a matrix $W$ instead of a vector this time. When we consider the function $F_i$, which gives us $y_i$ using a weight vector $\\vec w_i$. Our final output vector $\\vec y=[\\sigma(\\vec w_1^T\\vec x),\\dots,\\sigma(\\vec w_{10}^T\\vec x)]^T=\\sigma(Wx)$ where $W\\in\\mathbb{R}^{10\\times n}$ and $x\\in\\mathbb{R}^n=\\mathbb{R}^{n\\times 1}$\n",
    "\n",
    "The general formulation of a multi-class network with $n$ input features and $m$ output classes is\n",
    "$$\n",
    "F: \\mathbb{R}^n\\to\\mathbb{R}^{m}\\\\\n",
    "F(\\vec x,W)=\\sigma(W\\vec x)\n",
    "$$\n",
    "\n",
    "Now let's try to find $\\mathcal{D}[C]$ with respect to $W$. Now, it turns out to be significantly simpler to instead focus on finding the Jacobian with respect to every individual $\\vec w_i$, but keep in mind it ends up being equivelant. \n",
    "\n",
    "$$\n",
    "L=\\|F-y\\|^2\n",
    "\\\\\\mathcal{D}[C]=2(F_i-y_i)\\mathcal{D}[F_i-y_i]\n",
    "\\\\=2(F_i-y_i)\\mathcal{D}[F_i-y_i]\n",
    "\\\\=2(F_i-y_i)\\mathcal{D}[F_i]-\\mathcal{D}[y_i]\n",
    "\\\\=2(F_i-y_i)\\mathcal{D}[F_i]\n",
    "$$\n",
    "\n",
    "Taking a look at $\\mathcal{D}[F_i]$ in particular, setting $S=w_i^T\\vec x$ for convenience,\n",
    "\n",
    "$$\n",
    "\\mathcal{D}[F_i]=\\mathcal{D}[\\sigma(S)]\n",
    "\\\\=\\mathcal{D}[\\sigma](S)*\\mathcal{D}[S]\n",
    "\\\\=\\sigma(S)(1-\\sigma(S))*\\mathcal{D}[S]\n",
    "\\\\=\\sigma(S)(1-\\sigma(S))\\vec x^T\n",
    "$$\n",
    "\n",
    "therefore we have that \n",
    "$$\n",
    "\\\\\\mathcal{D}[C]=2(F_i-y_i)\\mathcal{D}[F_i-y_i]\n",
    "\\\\=2(\\sigma(w_i^T\\vec x)-y_i)\\sigma(w_i^T\\vec x)(1-\\sigma(w_i^T\\vec x))\\vec x^T\n",
    "\\\\=2(F_i-y_i)F_i(1-F_i)\\vec x^T\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Network\n",
    "\n",
    "All together, our model is still very simple. Simple models tend to fail in modeling the complexities of cecrtain data. It turns out, that includes the MNIST classification task! So, to increase our complexity, we'll add a new layer, known as a *hidden layer*. We refer to it as hidden because the values at those perceptrons don't necessarily hold physical significane. They need only be computationally relevent, but aren't required to make semantic sense. Hence, we generally don't directly observe them, and call them *hidden*. With this, we'll start referring to each perceptron as a *node*.\n",
    "\n",
    "Let's formulate a Neural Network with 1 *hidden layer* with $l$ *nodes*. How does this hidden layer actually come into play, mathematically and computationally? It can be thought of as an intermediate step. Where before we had \n",
    "\n",
    "$$\n",
    "F: \\mathbb{R}^n\\to\\mathbb{R^m}\\\\\n",
    "F(\\vec x,W)=\\sigma(W\\vec x)\n",
    "$$\n",
    "\n",
    "We now instead have: \n",
    "\n",
    "$$\n",
    "G: \\mathbb{R}^n\\to\\mathbb{R}^l\\\\\n",
    "G(\\vec x,W_1)=\\sigma(W_1\\vec x) \\text{ where } W_1\\in\\mathbb{R}^{l\\times n}\\\\\n",
    "\\\\\n",
    "H: \\mathbb{R}^l\\to\\mathbb{R^m}\\\\\n",
    "H(\\vec x,W_2)=\\sigma(W_2\\vec x) \\text{ where } W_2\\in\\mathbb{R}^{m\\times l}\\\\\n",
    "\\\\\n",
    "\\text{hence}\\\\\n",
    "\\\\\n",
    "F: \\mathbb{R}^n\\to\\mathbb{R^m}\\\\\n",
    "F(\\vec x, W_1,W_2)=H\\circ G\n",
    "\\\\=H(G(\\vec x, W_1), W_2)\n",
    "\\\\=H(\\sigma(W_1\\vec x), W_2)\n",
    "\\\\=\\sigma(W_2\\sigma(W_1\\vec x))\n",
    "$$\n",
    "\n",
    "This is how we build **deep** networks. We repeatedly apply these relatively simple layers, building up a progressively more complex representation until we reach a sufficient amount of complexity for our particular task.\n",
    "\n",
    "To review, a simple perceptron can be considered a *node*. Multiple nodes when placed together are referred to as *layers*. The layers excluding the input and output are referred to as *hidden layers*. When stacking multiple hidden layers on top of each other, we build a *Deep Neural Network*.\n",
    "\n",
    "This is still only the tip of the iceberg, and we'll explore all the nuances and crazy architectures which stem from this basic principle of repeatedly stacking on complexities to build a model, but for now, we'll dive a bit deeper into the mathematics of it all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Backpropagation is the heart of deep learning. Put simply, backpropogation is following the error in a system, and assigning blame where blame is due. Even more simply, it's the chain rule.\n",
    "\n",
    "Think back to how we optimized our single perceptron. To optimize a parameter $p$, you need the gradient of $L$ with respect to $p$. In a more general sense, you need the Jacobian since we'll be dealing with tensor parameters, not just vectors. So in our above model with a single hidden layer, we now need two different values: $\\mathcal{D}[C]$ with respect to $W_1$ AND $W_2$ Let's try to calculate that. Similarly to the no hidden layer case, we will prefer to look at a single row of our weights at a time. We'll start with respect to $(W_2)_i=\\vec w_{2,i}$\n",
    "\n",
    "$$\n",
    "C=\\|F-y\\|^2\n",
    "\\\\\\mathcal{D}[C]=2(F_i-y_i)\\mathcal{D}[F_i-y_i]\n",
    "\\\\=2(F_i-y_i)\\mathcal{D}[F_i]-\\mathcal{D}[y_i]\n",
    "\\\\=2(F_i-y_i)\\mathcal{D}[F_i]\n",
    "$$\n",
    "\n",
    "Taking a look at $\\mathcal{D}[F_i]$ in particular, setting $S_i=\\vec w_{2,i}G$ for convenience,\n",
    "\n",
    "$$\n",
    "\\mathcal{D}[F_i]\n",
    "\\\\=\\mathcal{D}[\\sigma(S_i)]\n",
    "\\\\=\\mathcal{D}[\\sigma](S_i)*\\mathcal{D}[S_i]\n",
    "\\\\=\\sigma(S_i)(1-\\sigma(S_i))G\n",
    "$$\n",
    "\n",
    "\n",
    "Notice that the Jacobians for the weights in $W_2$ stops at $G$. That's because, with respect to $W_2\\text{, }G$ is constant! But that also leads into an interesting system. Now $F$ depends on $W_2$, which depends on $G$, and that subsequently depends on $W_1$. That means that when we want to figure out the weights $W_1$, it suffices to consider that \n",
    "$$\n",
    "\\frac{\\partial C}{\\partial \\vec w_{1,i}}=\\frac{\\partial C}{\\partial W_2}\\frac{\\partial W_2}{\\partial w_{1,i}}\n",
    "$$\n",
    "This is just an application of the chain rule, and the premise of Backpropagation. What this really means is that, since we have to compute $\\frac{\\partial L}{W_2}$ anyways, we can save that information to speed up the computation of $\\frac{\\partial L}{\\partial \\vec W_1}$ This may seem trivial in this small scale, but when running computations for **millions** of weights, this brings the problem from the realm of impossibility to the realm of smart-phone-compatible-computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a point of clarification, the notation we used until now is great, and is the ideal go-to technique when analysizing many mechanisms of machine learningm, including activation functions, layers, modules and more, but it becomes very cumbersome for larger networks when talking about every single $\\frac{\\partial L}{\\partial \\vec w_{1,i}}$ term. Hence we'll be changing notation and processes a little bit when talking about computing the backpropagation algorithm.\n",
    "\n",
    "### New Notation\n",
    "First, we'll consider a network of $l$-layers, with a not-necessarily-fixed number of nodes per layer. So the network could look like $784\\to 256 \\to 100 \\to 256 \\to 32 \\to 10$. We will refer to the *output* of node $j$ in layer $l$ as $a_j^l$. We'll also interchangeably use this to refer to the node itself, but context ought to make it clear how we're using it. We'll also define the *bias* at layer $l$ to node $j$ as $b^l_j$\n",
    "\n",
    "**Note**: the superscripts serve as indices, not as a \"powers\" or exponents.\n",
    "\n",
    "Similarly, we will define the weight *from* node $a^{l-1}_k$ *to* $a^l_j$ as $w^l_{jk}$ \n",
    "\n",
    "Assume $\\sigma: \\mathbb{R}\\to\\mathbb{R}$ is a general activation function. For now its fine to just imagine the sigmoid function, but there are many more. \n",
    "\n",
    "In this way, we can write the equation for $a^l_j$ as $$a^l_j=\\sigma(\\sum_k(w^l_{jk}a^{l-1}_k)+b^l_j)$$\n",
    "\n",
    "For convenience, we will define $z^l_j=\\sum_k(w^l_{jk}a^{l-1}_k)+b^l_j$ so that $a^l_j=\\sigma(z^l_j)$\n",
    "\n",
    "We've defined a lot of different terms, so please make sure to take a good look at them and start to get comfortable with them before moving on to the next section. Overall, we've defined:\n",
    "+ $a^l_j$\n",
    "+ $b^l_j$\n",
    "+ $w^l_{jk}$\n",
    "+ $z^l_j$\n",
    "\n",
    "\n",
    "Often times, we'll want to not just consider the individual scalar values mentioned above, but their layer-wise vectors. That is to say, if we have $N$ nodes in layer $l$, then $a^l\\in\\mathbb{R}^N$ is an $N$-dimensional vector. Similarly, if we have $N$ nodes in layer $l-1$ and $M$ nodes in layer $l$, then $w^l\\in\\mathbb{R}^{N\\times M}$. In this way, dropping one of indices is equivelant to considering the tensor formed by that quantity across the indices. This cleans up our equations a bit, and we get that \n",
    "$$z^l=w^la^{l-1}+b^l$$\n",
    "and so\n",
    "$$a^l=\\sigma(z^l)$$\n",
    "\n",
    "### A Bit More About Cost\n",
    "Referring to our output layer as layer $L$, we can actually rewrite our cost function as \n",
    "$$\n",
    "C(\\vec x_i)=\\|y_i-a^L(x_i)\\|^2\n",
    "$$\n",
    "\n",
    "From experience, we saw that at the end of all our derivations, we end up with a constant $2$ multiplying everything, so in order to deal with that for our convenience, we can redefine C as follows\n",
    "$$\n",
    "C(\\vec x_i)=\\frac{1}{2}\\|y_i-a^L(x_i)\\|^2\n",
    "$$\n",
    "\n",
    "Multiplying it with a positive constant doesn't change any properties of the loss function, so it's perfectly acceptable to do so in order to make the computation a bit neater. Keep in mind that we don't compute the cost for *only* one input value at a time. We do so in *batches*, and hence for a batch $D$, the cost is then\n",
    "$$\n",
    "C=\\frac{1}{2}\\sum_{\\vec x\\in D}\\|y(\\vec x)-a^L(\\vec x)\\|^2\n",
    "$$\n",
    "\n",
    "With that being said, for analysis purposes it suffices to consider the cost for an arbitrary *fixed* input, since at the end we can just average all the costs.\n",
    "\n",
    "### Computing Layer Error\n",
    "Ultimately, we want to compute $\\frac{\\partial C}{\\partial w^l_{jk}}$ and $\\frac{\\partial C}{\\partial b^l_j}$. Before going directly into that, it's easier to first define an intermediate value $\\delta^l_j$ which is *the error in node $j$ in layer $l$.* We'll start with calculating that for a particular layer, namely the last one $L$. Formally, $\\delta^L_j=\\frac{\\partial C}{\\partial z^L_j}$. So how do we compute $\\frac{\\partial C}{\\partial z^L_j}$? Well, we'll expand it using the chain rule! \n",
    "$$\n",
    "\\delta^L_j=\\frac{\\partial C}{\\partial z^L_j}=\\frac{\\partial C}{\\partial a^L_j}\\frac{\\partial a^L_j}{\\partial z^L_j}=\\frac{\\partial C}{\\partial a^L_j}\\sigma'(z^L_j) \\tag*{(BP1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both those values are fairly easy to directly compute. In the case of sigmoid activation, we can replace $\\sigma'(z^L_j)=\\sigma(z^L_j)(1-\\sigma(z^L_j))=a^L_j(1-a^L_j)$. With our particular $L^2$ cost function, \n",
    "$$\n",
    "\\frac{\\partial C}{\\partial a^l_j}=\\frac{\\partial}{\\partial a^l_j}\\frac{1}{2}\\|y_j-a^L_j\\|^2=(a^L_j-y_j)\n",
    "$$\n",
    "\n",
    "**Aside:** For convenience, we'll define a new binary operator known as the Hadamard Product $\\vec x\\odot\\vec y=\\vec z$ where $\\forall j, z_j=x_jy_j$\n",
    "\n",
    "**Aside:** For convenience, we'll define a new term $\\nabla_a C$ as a vector where $(\\nabla_a C)_j=\\frac{\\partial C}{\\partial a^L_j}$\n",
    "\n",
    "We can then rewrite \n",
    "$$\n",
    "\\delta^L=\\nabla_a C\\odot\\sigma'(z^L)\n",
    "$$\n",
    "\n",
    "In particular, we note that for our $L^2$ cost, we have that \n",
    "$$\n",
    "\\nabla_a C=(a^L-y)\n",
    "$$\n",
    "\n",
    "therefore BP1 simplifies to\n",
    "$$\n",
    "\\delta^L=(a^L-y)\\odot\\sigma'(z^L) \\tag*{(BP1*)}\n",
    "$$\n",
    "\n",
    "These kinds of calculations have become *incredibly* optimized through the efforts of packages like numpy, PyTorch, numba, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using $\\delta^L$, we can compute $\\delta^{L-1}$, then $\\delta^{L-2}$ and so on. So in general, we want a formula for $\\delta^{l}$ given ${\\delta^{l+1}}$. We find that in fact \n",
    "\n",
    "$$\n",
    "\\delta^{l}=((w^{l+1})^T\\delta^{l+1})\\odot\\sigma'(z^l) \\tag*{(BP2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have the necessary tools and values to talk about the partials with respect to our learnable parameter: bias and the weights. Both will be proportional to our $\\delta^l_j$ terms, but scaled differently.\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial b^l_j}=\\delta^l_j \\tag*{(BP3)}\n",
    "$$\n",
    "Similarly, \n",
    "$$\n",
    "\\frac{\\partial C}{\\partial w^l_{jk}}=a^{l-1}_k\\delta^l_j \\tag*{(BP4)}\n",
    "$$\n",
    "\n",
    "Conceptually, we can interpret the latter as \n",
    "$$\n",
    "\\frac{\\partial C}{\\partial w^l_{jk}}=a_{in}\\delta_{out} \\tag*{}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BackPropEq](http://neuralnetworksanddeeplearning.com/images/tikz21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Graphs\n",
    "\n",
    "For a wonderful discussion about the basics of computational graphs, see https://colah.github.io/posts/2015-08-Backprop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
